{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "K = tf.keras.backend\n",
    "EarlyStopping = tf.keras.callbacks.EarlyStopping\n",
    "ReduceLROnPlateau = tf.keras.callbacks.ReduceLROnPlateau\n",
    "TensorBoard = tf.keras.callbacks.TensorBoard\n",
    "\n",
    "proj_dir = os.environ['CMS_ROOT']\n",
    "sys.path.append(proj_dir)\n",
    "from utils.utils import model_summary_to_string, args_to_dict, write_dnn_perf_metrics\n",
    "from utils.logging import Logger\n",
    "from utils.keras_callbacks import KerasRocAucCallback\n",
    "from utils.data import load_data, load_sampled_data, get_embedded_data\n",
    "from utils.mlp import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# Parse CLI Args & Create DNN Config\n",
    "############################################\n",
    "\n",
    "config = {}\n",
    "hidden_layers_markup = '128+64'\n",
    "config['hidden_layers'] = [64, 64]\n",
    "config['learn_rate'] = 1e-3\n",
    "config['batch_size'] = 128\n",
    "config['dropout_rate'] = 0.5\n",
    "config['batchnorm'] = True\n",
    "epochs = 25\n",
    "\n",
    "# embedding_path=os.path.join(proj_dir, 'data', 'skipgram-e300-w5-i100.kv')\n",
    "embedding_type = 'onehot'\n",
    "drop_columns = ['state_code']\n",
    "\n",
    "sample_size = 200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# Define I/O Paths\n",
    "############################################\n",
    "\n",
    "now = datetime.datetime.today()\n",
    "\n",
    "validation_auc_outputs = 'validation-auc-results.csv'\n",
    "train_auc_outputs = 'train-auc-results.csv'\n",
    "results_file = 'results.csv'\n",
    "\n",
    "config_value = f'embedding:{embedding_type}-layers:{hidden_layers_markup}-learn_rate:{config.get(\"learn_rate\")}'\n",
    "config_value += f'-batch_size:{config.get(\"batch_size\")}-dropout_rate:{config.get(\"dropout_rate\")}-bathcnorm:{config.get(\"batchnorm\")}'\n",
    "\n",
    "if not os.path.isfile(train_auc_outputs):\n",
    "    results_header = 'config,' + ','.join([f'ep_{i}' for i in range(epochs)])\n",
    "    output_files = [train_auc_outputs, validation_auc_outputs]\n",
    "    output_headers = [results_header,results_header]\n",
    "    for file, header in zip(output_files, output_headers):\n",
    "        with open(file, 'w') as fout:\n",
    "            fout.write(header + '\\n')\n",
    "\n",
    "def write_results(file, results):\n",
    "    with open(file, 'a') as fout:\n",
    "        fout.write(results + '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# Initialize Logger\n",
    "############################################\n",
    "ts = now.strftime(\"%m%d%y-%H%M%S\")\n",
    "log_file = f'logs/{ts}-{config_value}.txt'\n",
    "logger = Logger(log_file)\n",
    "logger.log_time('Using ts: {ts}')\n",
    "logger.log_time(f'Outputs being written to {[validation_auc_outputs,train_auc_outputs]}')\n",
    "logger.write_to_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from path /Users/jujohnson/cms-data/raw/Medicare_PUF_PartB_2012to2017.csv.gz\n",
      "Loaded data with shape: (56818165, 12)\n",
      "Dropped nan, updated shape: (56818165, 12)\n",
      "Positive sample count: 36548 18.274%\n",
      "Negative sample count: 163452 81.726%\n",
      "Using columns Index(['gender', 'provider_type', 'hcpcs_code', 'line_srvc_cnt',\n",
      "       'bene_unique_cnt', 'bene_day_srvc_cnt', 'average_submitted_chrg_amt',\n",
      "       'average_medicare_payment_amt'],\n",
      "      dtype='object')\n",
      "Using onehot embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jujohnson/git/HCPCS-Embeddings-For-Fraud-Detection/utils/data.py:87: FutureWarning: DataFrame.to_sparse is deprecated and will be removed in a future version\n",
      "  df = df.to_sparse().to_coo().astype('float32')\n",
      "/Users/jujohnson/anaconda3/envs/tf.latest/lib/python3.6/site-packages/pandas/core/frame.py:3451: FutureWarning: SparseSeries is deprecated and will be removed in a future version.\n",
      "Use a Series with sparse values instead.\n",
      "\n",
      "    >>> series = pd.Series(pd.SparseArray(...))\n",
      "\n",
      "See http://pandas.pydata.org/pandas-docs/stable/user_guide/sparse.html#migrating for more.\n",
      "\n",
      "  return klass(values, index=self.index, name=items, fastpath=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded data shape: (200000, 7633)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<utils.logging.Logger at 0x7fe163c435f8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_sampled_data(sample_size)\n",
    "\n",
    "# drop columns, onehot encode, or lookkup embeddings\n",
    "x, y = get_embedded_data(data, embedding_type, None, drop_columns)\n",
    "\n",
    "del data\n",
    "logger.log_time(f'Loaded embedded data with shape {x.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# Train/Test Split & Normalize\n",
    "############################################\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "# del x, y\n",
    "scaler = MaxAbsScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<160000x7633 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 1279997 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sparse matrix length is ambiguous; use getnnz() or shape[0]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-3ca5a81e845c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.shuffle\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf.latest/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;31m# non-zeros is more important.  For now, raise an exception!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         raise TypeError(\"sparse matrix length is ambiguous; use getnnz()\"\n\u001b[0m\u001b[1;32m    297\u001b[0m                         \" or shape[0]\")\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: sparse matrix length is ambiguous; use getnnz() or shape[0]"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_auc_callback = KerasRocAucCallback(x_test, y_test, True, logger)\n",
    "train_auc_callback = KerasRocAucCallback(x_train, y_train)\n",
    "early_stopping = EarlyStopping(monitor='val_auc', min_delta=0.001, patience=10, mode='max')\n",
    "tensorboard_dir = f'tensorboard/{ts}-{config_value}'\n",
    "tensorboard = TensorBoard(log_dir=f'{tensorboard_dir}', write_graph=False)\n",
    "callbacks = [validation_auc_callback, train_auc_callback, early_stopping, tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      " 192/1250 [===>..........................] - ETA: 57s - loss: 0.4978"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "# Training\n",
    "############################################\n",
    "K.clear_session()\n",
    "input_dim = x_train.shape[1]\n",
    "model = create_model(input_dim, config)\n",
    "\n",
    "logger.log_time('Starting training...').write_to_file()\n",
    "\n",
    "if 'onehot' in embedding_type:\n",
    "  training_generator = DataGenerator(x_train, y_train, batch_size=batch_size)\n",
    "  validation_generator = DataGenerator(x_test, y_test, batch_size=batch_size)\n",
    "  history = model.fit_generator(\n",
    "    epochs=epochs, generator=training_generator,\n",
    "    validation_data=validation_generator,\n",
    "    use_multiprocessing=True,\n",
    "    callbacks=callbacks,\n",
    "    workers=1)\n",
    "else:\n",
    "  history = model.fit(x_train, y_train, epochs=epochs, callbacks=callbacks, verbose=1)\n",
    "\n",
    "logger.log_time('Trainin complete!').write_to_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# Write Results\n",
    "############################################\n",
    "\n",
    "prefix = f'{config_value}'\n",
    "validation_aucs = np.array(history.history['val_auc'], dtype=str)\n",
    "write_results(validation_auc_outputs, f'{prefix},{\",\".join(validation_aucs)}')\n",
    "train_aucs = np.array(history.history['train_auc'], dtype=str)\n",
    "write_results(train_auc_outputs, f'{prefix},{\",\".join(train_aucs)}')\n",
    "\n",
    "\n",
    "minority_size = (y_train == 1).sum() / len(y_train) * 100\n",
    "threshold = minority_size / 100\n",
    "\n",
    "y_prob = model.predict(x_test)\n",
    "write_dnn_perf_metrics(y_test, y_prob, threshold, config_value, 2, 64, final_results)\n",
    "\n",
    "# free some memory\n",
    "del history, x_test, y_test, x_train, y_train\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
